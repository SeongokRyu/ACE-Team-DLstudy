{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will practice the usage of convolution operations. \n",
    "Since the output after appyling convolution operations depends on the parameters, such as a filter size, channel size, and filter size.\n",
    "Thus, this exercise amis to readers be familiar with conv operations.\n",
    "\n",
    "Firstly, let's import tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most of convents, such as VGG-Net, ResNet and others, convolution, max- or average- pooling operations are widely used. \n",
    "\n",
    "Let's assume that inputs to our model has a shape [batch_size, height, width, # of channels], in this case [None, 32, 32, 3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(?, 32, 32, 3) dtype=float32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link for the documentation of conv2d operation is given as below: https://www.tensorflow.org/api_docs/python/tf/layers/conv2d.\n",
    "\n",
    "Let's investigate the change of tensor shape after applying a basic 3x3 convolution with filter_size=16 and stride=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 15:00:11.167540 139799745857280 deprecation.py:323] From <ipython-input-3-74add751a9a4>:1: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0801 15:00:11.172342 139799745857280 deprecation.py:506] From /home/wykgroup/appl/anaconda3/envs/ML_study/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d/BiasAdd:0' shape=(?, 30, 30, 16) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.layers.conv2d(x, filters=16, kernel_size=3, strides=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we apply the 3x3 convolution without zero padding (which is a default option of tf.layers.conv2d), we can see that the height and width of image inputs are changed from 32 to 30 and the number of channels is changed from 3 to 16. \n",
    "\n",
    "In most convnets, they aims to maintain the height and width of features but only to change number of channels and reduce the size of feature maps by applying pooling operations. \n",
    "For this purpose, we should apply zero-paddings in convolutions.\n",
    "\n",
    "![](convolution_padding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_1/BiasAdd:0' shape=(?, 32, 32, 16) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.layers.conv2d(x, filters=16, kernel_size=3, strides=1, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the height and width are not altered. \n",
    "\n",
    "What will be happend if we apply a convolution with stride=2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_2/BiasAdd:0' shape=(?, 15, 15, 16) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.layers.conv2d(x, filters=16, kernel_size=3, strides=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_3/BiasAdd:0' shape=(?, 16, 16, 16) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.layers.conv2d(x, filters=16, kernel_size=3, strides=2, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that applying a convolution with a stride=2 and a zero-padding changes the height and width as a half. Some models implement the down-sampling of feature maps by applying a convolution with a stride=2.\n",
    "\n",
    "![](convolution_pooling.jpeg)\n",
    "\n",
    "Next we will see the effect of pooling operations, mostly used for down-samplings. \n",
    "The documentations for max- and average- pooling are given as belows: \n",
    "Max-pooling2d: https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d\n",
    "Average-pooling2d: https://www.google.com/search?client=firefox-b-d&q=tf+average+pooling\n",
    "\n",
    "The shape change after applying pooling operation is same for those two different poolings with same parameter setting.\n",
    "\n",
    "To downsample an input image as a half of its original size, max- or average- pooling of pool_size=2 and strides=2 is usually used. Let's see the change of shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0801 15:00:11.582760 139799745857280 deprecation.py:323] From <ipython-input-7-99515e918c53>:1: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'max_pooling2d/MaxPool:0' shape=(?, 16, 16, 3) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.layers.max_pooling2d(x, pool_size=2, strides=2, padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0801 15:00:11.704526 139799745857280 deprecation.py:323] From <ipython-input-8-245eb0b817e4>:1: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.AveragePooling2D instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'average_pooling2d/AvgPool:0' shape=(?, 16, 16, 3) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.layers.average_pooling2d(x, pool_size=2, strides=2, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We investigated how convolution and pooling operations working. \n",
    "\n",
    "For an example, let's build the VGG-Net as original one used for the ImageNet challenge. \n",
    "\n",
    "![](vggnet.png)\n",
    "\n",
    "The VGG-Net is composed of sequential combination of convolution, pooling, and dense layers. \n",
    "For an easiler implementation, let us define those operations as functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x, filters, kernel_size=3, strides=1, padding='same', activation=tf.nn.relu, use_bias=True):\n",
    "   return tf.layers.conv2d(x, \n",
    "                           filters=filters, \n",
    "                           kernel_size=kernel_size, \n",
    "                           strides=strides,\n",
    "                           padding=padding, \n",
    "                           activation=activation,\n",
    "                           use_bias=use_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool(x, pool_size=2, strides=2, padding='same'):\n",
    "    return tf.layers.max_pooling2d(x, \n",
    "                                   pool_size=pool_size, \n",
    "                                   strides=strides, \n",
    "                                   padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(x, hidden_dim, activation=None):\n",
    "    return tf.layers.dense(x, \n",
    "                           units=hidden_dim, \n",
    "                           activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_net(x):\n",
    "    filters_list = [64, 128, 256, 512]\n",
    "    hidden_dim_list = [4096, 1000]\n",
    "    \n",
    "    x = conv(x, filters_list[0])\n",
    "    print (x)\n",
    "    x = conv(x, filters_list[0])\n",
    "    print (x)\n",
    "    x = pool(x)\n",
    "    print (x)\n",
    "\n",
    "    \n",
    "    x = conv(x, filters_list[1])\n",
    "    print (x)\n",
    "    x = conv(x, filters_list[1])\n",
    "    print (x)\n",
    "    x = pool(x)\n",
    "    print (x)\n",
    "    \n",
    "    x = conv(x, filters_list[2])\n",
    "    print (x)\n",
    "    x = conv(x, filters_list[2])\n",
    "    print (x)\n",
    "    x = conv(x, filters_list[2])\n",
    "    print (x)\n",
    "    x = pool(x)\n",
    "    print (x)\n",
    "    \n",
    "    x = conv(x, filters_list[3])\n",
    "    print (x)\n",
    "    x = conv(x, filters_list[3])\n",
    "    print (x)\n",
    "    x = conv(x, filters_list[3])\n",
    "    print (x)\n",
    "    x = pool(x)\n",
    "    print (x)\n",
    "    \n",
    "    x = conv(x, filters_list[3])\n",
    "    print (x)\n",
    "    x = conv(x, filters_list[3])\n",
    "    print (x)\n",
    "    x = conv(x, filters_list[3])\n",
    "    print (x)\n",
    "    x = pool(x)\n",
    "    print (x)\n",
    "    \n",
    "    x = tf.layers.flatten(x)\n",
    "    print (x)\n",
    "    x = dense(x, hidden_dim_list[0], activation=tf.nn.relu)\n",
    "    print (x)\n",
    "    x = dense(x, hidden_dim_list[0], activation=tf.nn.relu)\n",
    "    print (x)\n",
    "    logits = dense(x, hidden_dim_list[1])\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(?, 32, 32, 3) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vgg = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0801 15:00:11.973469 139799745857280 deprecation.py:323] From <ipython-input-12-417687362aea>:47: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d_4/Relu:0\", shape=(?, 224, 224, 64), dtype=float32)\n",
      "Tensor(\"conv2d_5/Relu:0\", shape=(?, 224, 224, 64), dtype=float32)\n",
      "Tensor(\"max_pooling2d_1/MaxPool:0\", shape=(?, 112, 112, 64), dtype=float32)\n",
      "Tensor(\"conv2d_6/Relu:0\", shape=(?, 112, 112, 128), dtype=float32)\n",
      "Tensor(\"conv2d_7/Relu:0\", shape=(?, 112, 112, 128), dtype=float32)\n",
      "Tensor(\"max_pooling2d_2/MaxPool:0\", shape=(?, 56, 56, 128), dtype=float32)\n",
      "Tensor(\"conv2d_8/Relu:0\", shape=(?, 56, 56, 256), dtype=float32)\n",
      "Tensor(\"conv2d_9/Relu:0\", shape=(?, 56, 56, 256), dtype=float32)\n",
      "Tensor(\"conv2d_10/Relu:0\", shape=(?, 56, 56, 256), dtype=float32)\n",
      "Tensor(\"max_pooling2d_3/MaxPool:0\", shape=(?, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"conv2d_11/Relu:0\", shape=(?, 28, 28, 512), dtype=float32)\n",
      "Tensor(\"conv2d_12/Relu:0\", shape=(?, 28, 28, 512), dtype=float32)\n",
      "Tensor(\"conv2d_13/Relu:0\", shape=(?, 28, 28, 512), dtype=float32)\n",
      "Tensor(\"max_pooling2d_4/MaxPool:0\", shape=(?, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"conv2d_14/Relu:0\", shape=(?, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"conv2d_15/Relu:0\", shape=(?, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"conv2d_16/Relu:0\", shape=(?, 14, 14, 512), dtype=float32)\n",
      "Tensor(\"max_pooling2d_5/MaxPool:0\", shape=(?, 7, 7, 512), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0801 15:00:12.150186 139799745857280 deprecation.py:323] From <ipython-input-11-6686e59b8b73>:4: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"flatten/Reshape:0\", shape=(?, 25088), dtype=float32)\n",
      "Tensor(\"dense/Relu:0\", shape=(?, 4096), dtype=float32)\n",
      "Tensor(\"dense_1/Relu:0\", shape=(?, 4096), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_2/BiasAdd:0' shape=(?, 1000) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_net(x_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully implement the VGG-Net as shown in the above figure and confirm the shape change of tensors. Just put output logits from the network into the objective function for the optimization!\n",
    "\n",
    "For the last example, we will implement the residual block of PreActResNet, one of the variants of original residual network firtly proposed by Keiming He.\n",
    "\n",
    "![](preact_resnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x0, filters):\n",
    "    x = tf.layers.batch_normalization(x0)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = conv(x, filters, activation=None)\n",
    "    x = tf.layers.batch_normalization(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = conv(x, filters, activation=None)\n",
    "    \n",
    "    return x + x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_2:0' shape=(?, 32, 32, 3) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3]) # ex) CIFAR-10, 100\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_17/Conv2D:0' shape=(?, 32, 32, 64) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_conv = conv(x, filters=64, activation=None, use_bias=False)\n",
    "x_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0801 15:00:12.495867 139799745857280 deprecation.py:323] From <ipython-input-15-f82e21716cf3>:2: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(?, 32, 32, 64) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_residual = residual_block(x_conv, 64)\n",
    "x_residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully the basic residual block!\n",
    "But we would like to throw a question: what will be happend if the dimensionality of x0 and x in residual blocks are different? It can be happend if we want to change the shape of feature maps. \n",
    "How can we utilize the residual block for such cases?\n",
    "We remain this question for a homework. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next practice, we will implement overall pipeline of building classification models based on one of the variants of residual networks, Wide Residual Networks (WRN), with CIFAR-10 dataset.\n",
    "\n",
    "We would like readers to see some references for preliminaries.\n",
    "* Original resnet: https://arxiv.org/abs/1512.03385\n",
    "* Further study on skip-connection (PreActResNet): https://arxiv.org/abs/1603.05027\n",
    "* Wide ResNet: https://arxiv.org/abs/1605.07146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
